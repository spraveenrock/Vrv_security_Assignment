{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP Addresses:\n",
      "----------------------------------------\n",
      "IP Address           Request Count  \n",
      "----------------------------------------\n",
      "203.0.113.5          8              \n",
      "192.168.1.1          7              \n",
      "198.51.100.23        7              \n",
      "10.0.0.2             6              \n",
      "192.168.1.100        5              \n",
      "\n",
      "\n",
      "Most Frequently Accessed Endpoint:\n",
      "/login (Accessed 13 times)\n",
      "\n",
      "\n",
      "Suspicious Activity Detected:\n",
      "----------------------------------------\n",
      "IP Address           Failed Login Attempts\n",
      "----------------------------------------\n",
      "192.168.1.100        5              \n",
      "203.0.113.5          8              \n",
      "\n",
      "Analysis completed in 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from typing import Dict, Set, NamedTuple\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import mmap\n",
    "import os\n",
    "from itertools import islice\n",
    "import time\n",
    "\n",
    "class LogEntry(NamedTuple):\n",
    "    \"\"\"Immutable log entry structure for efficient memory usage\"\"\"\n",
    "    ip: str\n",
    "    endpoint: str\n",
    "    status_code: int\n",
    "    timestamp: datetime\n",
    "\n",
    "class OptimizedLogAnalyzer:\n",
    "    \"\"\"Memory-efficient and fast log analyzer\"\"\"\n",
    "    \n",
    "    # Compile regex pattern once for better performance\n",
    "    LOG_PATTERN = re.compile(\n",
    "        r'(\\d+\\.\\d+\\.\\d+\\.\\d+)[^\"]+\"\\w+ ([^ ]+)[^\"]+\"\\s+(\\d+)'\n",
    "    )\n",
    "    \n",
    "    def __init__(self, chunk_size: int = 8192):\n",
    "        \"\"\"\n",
    "        Initialize analyzer with configurable chunk size for reading\n",
    "        \n",
    "        Args:\n",
    "            chunk_size: Size of chunks to read from file (bytes)\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.ip_requests: Dict[str, int] = defaultdict(int)\n",
    "        self.endpoint_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.failed_logins: Dict[str, int] = defaultdict(int)\n",
    "        self.suspicious_ips: Set[str] = set()\n",
    "        \n",
    "    def _parse_line_fast(self, line: str) -> LogEntry | None:\n",
    "        \"\"\"Optimized line parser using pre-compiled regex\"\"\"\n",
    "        try:\n",
    "            match = self.LOG_PATTERN.search(line)\n",
    "            if not match:\n",
    "                return None\n",
    "                \n",
    "            ip, endpoint, status = match.groups()\n",
    "            return LogEntry(\n",
    "                ip=ip,\n",
    "                endpoint=endpoint,\n",
    "                status_code=int(status),\n",
    "                timestamp=datetime.now()  # Placeholder if needed\n",
    "            )\n",
    "        except (AttributeError, ValueError):\n",
    "            return None\n",
    "\n",
    "    def analyze_file(self, filepath: str, failed_threshold: int = 3) -> Dict:\n",
    "        \"\"\"\n",
    "        Memory-efficient file analysis using memory mapping\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to log file\n",
    "            failed_threshold: Threshold for suspicious activity\n",
    "            \n",
    "        Returns:\n",
    "            Dict containing analysis results\n",
    "        \"\"\"\n",
    "        file_size = os.path.getsize(filepath)\n",
    "        \n",
    "        with open(filepath, 'rb') as f:\n",
    "            # Memory map file for efficient reading\n",
    "            mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "            \n",
    "            # Process file in chunks\n",
    "            current_pos = 0\n",
    "            incomplete_line = ''\n",
    "            \n",
    "            while current_pos < file_size:\n",
    "                chunk = mm.read(self.chunk_size).decode('utf-8')\n",
    "                lines = (incomplete_line + chunk).split('\\n')\n",
    "                \n",
    "                # Save incomplete last line\n",
    "                incomplete_line = lines[-1]\n",
    "                \n",
    "                # Process complete lines\n",
    "                for line in lines[:-1]:\n",
    "                    entry = self._parse_line_fast(line)\n",
    "                    if not entry:\n",
    "                        continue\n",
    "                        \n",
    "                    # Update counters (all O(1) operations)\n",
    "                    self.ip_requests[entry.ip] += 1\n",
    "                    self.endpoint_counts[entry.endpoint] += 1\n",
    "                    \n",
    "                    if entry.status_code == 401:\n",
    "                        self.failed_logins[entry.ip] += 1\n",
    "                        if self.failed_logins[entry.ip] >= failed_threshold:\n",
    "                            self.suspicious_ips.add(entry.ip)\n",
    "                \n",
    "                current_pos = mm.tell()\n",
    "            \n",
    "            mm.close()\n",
    "        \n",
    "        # Get top results without full sorting\n",
    "        return {\n",
    "            'top_ips': self._get_top_n(self.ip_requests, 10),\n",
    "            'top_endpoints': self._get_top_n(self.endpoint_counts, 5),\n",
    "            'suspicious': list(self.suspicious_ips)\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_top_n(counter: Dict[str, int], n: int) -> list:\n",
    "        \"\"\"Get top N items without full sort (O(n) instead of O(n log n))\"\"\"\n",
    "        return sorted(counter.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    def save_results(self, results: Dict, output_file: str):\n",
    "        \"\"\"Efficient CSV writing with minimal memory usage\"\"\"\n",
    "        with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            # Write sections directly without storing in memory\n",
    "            writer.writerow(['Top IP Addresses by Request Count'])\n",
    "            writer.writerow(['IP Address', 'Request Count'])\n",
    "            writer.writerows(results['top_ips'])\n",
    "            \n",
    "            writer.writerow([])\n",
    "            writer.writerow(['Most Frequently Accessed Endpoint'])\n",
    "            writer.writerow(['Endpoint', 'Access Count'])\n",
    "            writer.writerow(results['top_endpoints'][0])  # Only top endpoint\n",
    "            \n",
    "            writer.writerow([])\n",
    "            writer.writerow(['Suspicious IPs'])\n",
    "            writer.writerow(['IP Address', 'Failed Login Attempts'])\n",
    "            writer.writerows((ip, self.failed_logins[ip]) \n",
    "                           for ip in results['suspicious'])\n",
    "\n",
    "def format_output(analyzer, results):\n",
    "    \"\"\"Format the analysis results for console output\"\"\"\n",
    "    # IP Addresses section\n",
    "    print(\"IP Addresses:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"{'IP Address':<20} {'Request Count':<15}\")\n",
    "    print(\"-\" * 40)\n",
    "    for ip, count in results['top_ips']:\n",
    "        print(f\"{ip:<20} {count:<15}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Most Accessed Endpoint section (highest only)\n",
    "    top_endpoint, top_count = results['top_endpoints'][0]\n",
    "    print(\"Most Frequently Accessed Endpoint:\")\n",
    "    print(f\"{top_endpoint} (Accessed {top_count} times)\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Suspicious Activity section\n",
    "    if results['suspicious']:\n",
    "        print(\"Suspicious Activity Detected:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"{'IP Address':<20} {'Failed Login Attempts':<15}\")\n",
    "        print(\"-\" * 40)\n",
    "        for ip in results['suspicious']:\n",
    "            print(f\"{ip:<20} {analyzer.failed_logins[ip]:<15}\")\n",
    "    else:\n",
    "        print(\"No suspicious activity detected.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Example usage with performance metrics\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    analyzer = OptimizedLogAnalyzer()\n",
    "    results = analyzer.analyze_file('sample.log')\n",
    "    \n",
    "    # Format and display results\n",
    "    format_output(analyzer, results)\n",
    "    \n",
    "    # Print performance metrics\n",
    "    print(f\"\\nAnalysis completed in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Save results to CSV\n",
    "    analyzer.save_results(results, 'log_analysis_results.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
